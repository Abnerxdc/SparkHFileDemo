#Admin Database Connection config
metaDbDriver=com.mysql.jdbc.Driver
metaDbUrl=jdbc:mysql://192.2.15.102:3306/liuchuli
metaDbUser=root
metaDbPassword=sa123456

#sparkConf
sparkconf.spark.master=local[2]
sparkconf.spark.sql.parquet.binaryAsString=true
sparkconf.spark.sql.parquet.int96AsTimestamp=true
sparkconf.spark.streaming.concurrentJobs=10
sparkconf.spark.app.name=HFileWritterTest
sparkconf.spark.streaming.stopGracefullyOnShutdown=true
sparkconf.spark.streaming.unpersist=true
sparkconf.spark.sqlshuffle.partitions=200
#sparkconf.spark.streaming.blockQueueSize=5
sparkconf.spark.streaming.receiver.maxRate=1
#sparkconf.spark.serializer=org.apache.spark.serializer.KryoSerializer
#sparkconf.spark.tryo.registrator=manager.MyRegisterKryo


sparkcontext.LogLevel=WARN

sparkstreaming.CacheUpdateIntervalSec=2000000
sparkstreaming.StreamProcessIntervalSec=60
sparkstreaming.ConcurrentJobs=10
sparkstreaming.CheckPointPath=/stream

#kafka-producer
output.kafka.producer.request.required.acks=1
output.kafka.producer.producer.type=sync
output.kafka.producer.serializer.class=kafka.serializer.StringEncoder

#kafka.port=9092

#stop sparkstreaming cmd
stopcmd=/work/bin/StreamAlertReport/run.sh stop

InputFilePath=./conf/ccc.csv

hbaseconf.hbase.master=192.168.1.106
hbaseconf.hbase.zookeeper.property.clientPort=2181
hbaseconf.hbase.zookeeper.quorum=192.168.1.106

hdfsPath=hdfs://192.168.1.106:8020

storeFileRootPath=/user/Abner

